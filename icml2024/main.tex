%%%%%%%% ICML 2024 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2024} with \usepackage[nohyperref]{icml2024} above.
\usepackage{hyperref}


% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
\usepackage{icml2024}

% If accepted, instead use the following line for the camera-ready submission:
% \usepackage[accepted]{icml2024}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}


% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{Submission and Formatting Instructions for ICML 2024}

\begin{document}

\twocolumn[
\icmltitle{Tuning 2D Latent Diffusion Models for 3D Generation}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2024
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Firstname1 Lastname1}{equal,yyy}
\icmlauthor{Firstname2 Lastname2}{equal,yyy,comp}
\icmlauthor{Firstname3 Lastname3}{comp}
\icmlauthor{Firstname4 Lastname4}{sch}
\icmlauthor{Firstname5 Lastname5}{yyy}
\icmlauthor{Firstname6 Lastname6}{sch,yyy,comp}
\icmlauthor{Firstname7 Lastname7}{comp}
%\icmlauthor{}{sch}
\icmlauthor{Firstname8 Lastname8}{sch}
\icmlauthor{Firstname8 Lastname8}{yyy,comp}
%\icmlauthor{}{sch}
%\icmlauthor{}{sch}
\end{icmlauthorlist}

\icmlaffiliation{yyy}{Department of XXX, University of YYY, Location, Country}
\icmlaffiliation{comp}{Company Name, Location, Country}
\icmlaffiliation{sch}{School of ZZZ, Institute of WWW, Location, Country}

\icmlcorrespondingauthor{Firstname1 Lastname1}{first1.last1@xxx.edu}
\icmlcorrespondingauthor{Firstname2 Lastname2}{first2.last2@www.uk}

% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{Machine Learning, ICML}

\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

%\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
\printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.

\begin{abstract}

\end{abstract}

\section{Introduction}

\section{Related Works}

\paragraph{Zero/One/Few-shot 3D Generation.}

\paragraph{Diffusion Models for 3D Generation.}
% 基于score蒸馏的方式
% DMV3D

\paragraph{Latent Diffusion Models.} 
% LDMs包含了两个关键组件，一个自动编码器以及一个潜变量去噪网络。
LDMs consist of two key components: an auto-encoder and a latent denoising network.
% 其中，自动编码器可以建立原始数据，例如图像到一个相对低维潜变量的双向映射。
the autoencoder can establish a bi-directional mapping from the space of the original data, such as high-resolution image space, to a low-dimensional latent space:
%
\begin{equation}
z = E(x), \tilde{x} = D(z)
\label{eq.1}
\end{equation}
%
where $E$ and $D$ are the encoder and decoder, respectively. 
%
The latent denoising network $\epsilon_\theta$ aims to denoise noisy latent given timestep $t$ and condition $y$. 
%
Its training objective is defined as:
\begin{equation}
L:=\mathbb{E}_{
\mathcal{E}(x),\epsilon\sim\mathcal{N}(0,1),t}
\Big[\|\epsilon-\epsilon_\theta(z_t,y,t)\|_2^2\Big],
\label{eq.2}
\end{equation}
%
where the noisy latent is obtained by $z_t = E(x) + \epsilon$.

During inference, we randomly sample $z_T \in \mathcal{N}(0,1)$. 
%
By continuously denoising $z_{t-1}=, t=T, T-1, \dots, 1$, we can obtain a latent satisfying condition $y$.
%
Then, we input the completely denoised latent $z_0$ into the decoder to get the high-resolution image $x = E(z_0)$.

\begin{equation}
L:=\mathbb{E}_{
\mathcal{X},\epsilon\sim\mathcal{N}(0,1),t}
\Big[\|\mathcal{X}_t - 
R(K(\mathcal{X}_t,c,y,t), c)\|_2^2\Big]
\label{eq.2}
\end{equation}


\begin{equation}
L:=\mathbb{E}_{
\mathcal{E}(\mathcal{X}),\epsilon\sim\mathcal{N}(0,1),t}
\Big[\|\mathcal{Z}_t - 
E(R(K(\mathcal{Z}_t,c,y,t), c))\|_2^2\Big]
\label{eq.2}
\end{equation}

\section{Multi-view 2D Latent Diffusion Models with 3D representation}


\subsection{Formulation}

\begin{equation}
L:=\mathbb{E}_{
\mathcal{E}(\mathcal{X}),\epsilon\sim\mathcal{N}(0,1),t}
\Big[\|\mathcal{Z}_t - 
E(R(K(\mathcal{Z}_t,c,y,t), c))\|_2^2\Big]
\label{eq.2}
\end{equation}


\begin{equation}
K(\mathcal{Z}_t,c,y,t) = D( \mathcal{Z}_{t}^F + \epsilon_\theta(\{\mathcal{Z}_{t}^F, \mathcal{Z}_t\},c,y,t)^F)
\label{eq.2}
\end{equation}

%三个关键点
%% 多视角diffusion
\paragraph{Multi-view Latent Diffusion}

%% clean 3D representation
\paragraph{Reconstruction-based denoising}


\subsection{Tuning from 2D Latent Diffusion Model}

\paragraph{Triplanes Latents}

\paragraph{Upsamplar}

\paragraph{NeuS-Rendering}

\paragraph{Latent space}

\subsection{Training Objectives}





% Acknowledgements should only appear in the accepted version.
% \section*{Acknowledgements}


\bibliography{example_paper}
\bibliographystyle{icml2024}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\appendix
\onecolumn
\section{You \emph{can} have an appendix here.}


\end{document}


% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was created
% by Iain Murray in 2018, and modified by Alexandre Bouchard in
% 2019 and 2021 and by Csaba Szepesvari, Gang Niu and Sivan Sabato in 2022.
% Modified again in 2023 and 2024 by Sivan Sabato and Jonathan Scarlett.
% Previous contributors include Dan Roy, Lise Getoor and Tobias
% Scheffer, which was slightly modified from the 2010 version by
% Thorsten Joachims & Johannes Fuernkranz, slightly modified from the
% 2009 version by Kiri Wagstaff and Sam Roweis's 2008 version, which is
% slightly modified from Prasad Tadepalli's 2007 version which is a
% lightly changed version of the previous year's version by Andrew
% Moore, which was in turn edited from those of Kristian Kersting and
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.
